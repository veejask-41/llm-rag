{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain_chroma import Chroma\n",
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain_community.document_loaders import PyPDFLoader\n",
    "# from pydantic import BaseModel, Field\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_core.runnables import RunnablePassthrough\n",
    "# from langchain_core.runnables import chain\n",
    "# from langchain.chains import create_history_aware_retriever\n",
    "# from langchain_core.prompts import MessagesPlaceholder\n",
    "# from langchain_core.messages import AIMessage, HumanMessage\n",
    "# from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "# import os\n",
    "\n",
    "# api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=api_key)\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",temperature=0.3, max_tokens=1000, api_key=api_key )\n",
    "# chat_history = []\n",
    "\n",
    "\n",
    "# # chroma db persist directory\n",
    "# persist_directory = \"local_chroma_db\"\n",
    "\n",
    "# # general information\n",
    "# vectorstore_general = Chroma(persist_directory=persist_directory, embedding_function=embeddings, collection_name=\"general\")\n",
    "# retriever_general = vectorstore_general.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "\n",
    "#  # sajith's manifesto\n",
    "# vectorstore_sajith = Chroma(persist_directory=persist_directory, embedding_function=embeddings, collection_name=\"sajith_premadasa\")\n",
    "# retriever_sajith = vectorstore_sajith.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "# # akd's manifesto\n",
    "# vectorstore_akd = Chroma(persist_directory=persist_directory, embedding_function=embeddings, collection_name=\"anura_kumara_dissanayake\")\n",
    "# retriever_akd = vectorstore_akd.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "# # ranil's manifesto\n",
    "# vectorstore_ranil = Chroma(persist_directory=persist_directory, embedding_function=embeddings, collection_name=\"ranil_wickramasinghe\")\n",
    "# retriever_ranil = vectorstore_ranil.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "# contextualize_q_system_prompt = (\n",
    "#     \"Given a chat history and the latest user question \"\n",
    "#     \"which might reference context in the chat history, \"\n",
    "#     \"formulate a standalone question which can be understood \"\n",
    "#     \"without the chat history. Do NOT answer the question, \"\n",
    "#     \"just reformulate it if needed and otherwise return it as is.\"\n",
    "# )\n",
    "\n",
    "# contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", contextualize_q_system_prompt),\n",
    "#         MessagesPlaceholder(\"chat_history\"),\n",
    "#         (\"human\", \"{input}\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# history_aware_retriever_general = create_history_aware_retriever(\n",
    "#     llm, retriever_general, contextualize_q_prompt\n",
    "# )\n",
    "\n",
    "# history_aware_retriever_sajith = create_history_aware_retriever(\n",
    "#     llm, retriever_sajith, contextualize_q_prompt\n",
    "# )\n",
    "\n",
    "# history_aware_retriever_akd = create_history_aware_retriever(\n",
    "#     llm, retriever_akd, contextualize_q_prompt\n",
    "# )\n",
    "\n",
    "# history_aware_retriever_ranil = create_history_aware_retriever(\n",
    "#     llm, retriever_ranil, contextualize_q_prompt\n",
    "# )\n",
    "\n",
    "# retrievers = {\n",
    "#     \"sajith_premadasa\": history_aware_retriever_sajith,\n",
    "#     \"anura_kumara_dissanayake\": history_aware_retriever_akd,\n",
    "#     \"ranil_wickramasinghe\": history_aware_retriever_ranil,\n",
    "# }\n",
    "\n",
    "# class SearchAndCompare(BaseModel):\n",
    "#     \"\"\"Search for information about a person or compare informations about persons.\"\"\"\n",
    "#     queryType: str = Field(\n",
    "#         ...,\n",
    "#         description=\"Query type. Should be `search` or `compare` or `general`. if there's only one person name it's search, if there are many person's name it's compare, or it can be a general question which does not require any specific person\",)\n",
    "\n",
    "#     query: str = Field(\n",
    "#         ...,\n",
    "#         description=\"Query to look up or query to compare\",\n",
    "#     )\n",
    "\n",
    "#     candidates: int = Field(\n",
    "#         ...,\n",
    "#         description=\"Number of persons to search or compare. can be 0 for general questions\",\n",
    "#     )\n",
    "\n",
    "#     person1: str = Field(\n",
    "#         ...,\n",
    "#         description=\"Person to look things up for or persons to compare. Should be `sajith_premadasa` or `anura_kumara_dissanayake` or `ranil_wickramasinghe` or can be 'null'.\",\n",
    "#     )\n",
    "#     person2: str = Field(\n",
    "#         ...,\n",
    "#         description=\"Person to look things up for or persons to compare. Should be `sajith_premadasa` or `anura_kumara_dissanayake` or `ranil_wickramasinghe` or can be 'null'.\",\n",
    "#     )\n",
    "#     person3: str = Field(\n",
    "#         ...,\n",
    "#         description=\"Person to look things up for or persons to compare. Should be `sajith_premadasa` or `anura_kumara_dissanayake` or `ranil_wickramasinghe` or can be 'null'.\",\n",
    "#     )\n",
    "\n",
    "# structured_llm_query = llm.with_structured_output(SearchAndCompare)\n",
    "\n",
    "# @chain\n",
    "# def query_analyzer_chain(question):\n",
    "#     system_query = \"\"\"You have the ability to determine whether the user question is general, or it is related to a specific person or it is a comparison between multiple persons. if you can't find the type set it as general\"\"\"\n",
    "#     prompt_query = ChatPromptTemplate.from_messages(\n",
    "#         [\n",
    "#             (\"system\", system_query),\n",
    "#             (\"human\", \"{question}\"),\n",
    "#         ]\n",
    "#     )\n",
    "#     prompt_query = prompt_query.format_messages(question=question)\n",
    "#     response = structured_llm_query.invoke(prompt_query)\n",
    "\n",
    "#     return response\n",
    "\n",
    "\n",
    "# @chain\n",
    "# def qa_chain(question):\n",
    "#     response = query_analyzer_chain.invoke(question)\n",
    "#     # print(response)\n",
    "#     if response.queryType == \"search\" or response.queryType == \"compare\":\n",
    "#         if response.queryType == \"search\":\n",
    "#             retriever = retrievers[response.person1]\n",
    "#             retrieved_docs = retriever.invoke({\"input\":response.query, \"chat_history\": chat_history})\n",
    "\n",
    "#             prompt = (\n",
    "#             \"system :\"\n",
    "#             \"You are an assistant for question-answering tasks. \"\n",
    "#             \"Use the following pieces of retrieved context to answer \"\n",
    "#             \"the question. If you don't know the answer, say that you \"\n",
    "#             \"don't know.\"\n",
    "#             \"\\n\\n\"\n",
    "#             \"{context}\"\n",
    "#             \"\\n\\n\"\n",
    "\n",
    "#             \"chat_history :\" \n",
    "#             \"{chat_history}\"\n",
    "\n",
    "#             \"human :\"\n",
    "#             \"{question}\"\n",
    "#             ).format(context=retrieved_docs, question=question, chat_history=chat_history)\n",
    "\n",
    "#             result = llm.invoke(prompt)\n",
    "\n",
    "#             return result\n",
    "    \n",
    "#         elif response.queryType == \"compare\":\n",
    "#             retriever1 = retrievers[response.person1]\n",
    "#             retrieved_docs1 = retriever1.invoke({\"input\":response.query, \"chat_history\": chat_history})\n",
    "\n",
    "#             if response.person2 != 'null':\n",
    "#                 retriever2 = retrievers[response.person2]\n",
    "#                 retrieved_docs2 = retriever2.invoke({\"input\":response.query, \"chat_history\": chat_history})\n",
    "#             else:\n",
    "#                 retrieved_docs2 = ''\n",
    "\n",
    "#             if response.person3 != 'null':\n",
    "#                 retriever3 = retrievers[response.person3]\n",
    "#                 retrieved_docs3 = retriever3.invoke({\"input\":response.query, \"chat_history\": chat_history})\n",
    "#             else:\n",
    "#                 retrieved_docs3 = ''\n",
    "\n",
    "#             prompt = (\n",
    "#             \"system :\"\n",
    "#             \"You are an assistant for comparing manifestos. \"\n",
    "#             \"Use the following pieces of retrieved context from different manifestos to answer \"\n",
    "#             \"the question. If you don't know the answer, say that you \"\n",
    "#             \"don't know.\"\n",
    "#             \"\\n\\n\"\n",
    "#             \"{context1}\"\n",
    "#             \"\\n\\n\"\n",
    "#             \"{context2}\"\n",
    "#             \"\\n\\n\"\n",
    "#             \"{context3}\"\n",
    "#             \"\\n\\n\"\n",
    "\n",
    "#             \"chat_history :\" \n",
    "#             \"{chat_history}\"\n",
    "\n",
    "#             \"human :\"\n",
    "#             \"{question}\"\n",
    "#             ).format(context1=retrieved_docs1, context2=retrieved_docs2, context3=retrieved_docs3, question=question, chat_history=chat_history)\n",
    "\n",
    "#             result = llm.invoke(prompt)\n",
    "\n",
    "#             return result\n",
    "#     else:\n",
    "#         retriever = history_aware_retriever_general\n",
    "#         retrieved_docs = retriever.invoke({\"input\":response.query, \"chat_history\": chat_history})\n",
    "\n",
    "#         prompt = (\n",
    "#             \"system :\"\n",
    "#             \"You are an assistant for question-answering tasks related to srilankan election.\"\n",
    "#             \"Use the following pieces of retrieved context to answer \"\n",
    "#             \"the question. If you don't know the answer, say that you \"\n",
    "#             \"don't know.\"\n",
    "#             \"or if the question is not much related to srilankan election say that this question is not related to srilankan election ass a election chatbot i can't provide you with answer this.\"\n",
    "#             \"\\n\\n\"\n",
    "#             \"{context}\"\n",
    "#             \"\\n\\n\"\n",
    "\n",
    "#             \"chat_history :\" \n",
    "#             \"{chat_history}\"\n",
    "\n",
    "#             \"human :\"\n",
    "#             \"{question}\"\n",
    "#             ).format(context=retrieved_docs, question=question, chat_history=chat_history)\n",
    "\n",
    "#         result = llm.invoke(prompt)\n",
    "#         return result\n",
    "\n",
    "# def chatbot(question):\n",
    "#     result = qa_chain.invoke(question)\n",
    "    \n",
    "#     # retains only last 3 conversations in history\n",
    "#     if len(chat_history) == 6:\n",
    "#         chat_history.pop(0)\n",
    "#         chat_history.pop(0)\n",
    "    \n",
    "#     chat_history.extend([\n",
    "#             HumanMessage(content=question),\n",
    "#             AIMessage(content=result.content),\n",
    "#         ])\n",
    "    \n",
    "#     return result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain_chroma import Chroma\n",
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain_community.document_loaders import PyPDFLoader\n",
    "# from pydantic import BaseModel, Field\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_core.runnables import RunnablePassthrough\n",
    "# from langchain_core.runnables import chain\n",
    "# from langchain.chains import create_history_aware_retriever\n",
    "# from langchain_core.prompts import MessagesPlaceholder\n",
    "# from langchain_core.messages import AIMessage, HumanMessage\n",
    "# from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "# import os\n",
    "\n",
    "# api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=api_key)\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",temperature=0.3, max_tokens=1000, api_key=api_key )\n",
    "# chat_history = []\n",
    "\n",
    "\n",
    "# # chroma db persist directory\n",
    "# persist_directory = \"local_chroma_db\"\n",
    "\n",
    "# # general information\n",
    "# vectorstore_general = Chroma(persist_directory=persist_directory, embedding_function=embeddings, collection_name=\"general\")\n",
    "# retriever_general = vectorstore_general.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "\n",
    "#  # sajith's manifesto\n",
    "# vectorstore_sajith = Chroma(persist_directory=persist_directory, embedding_function=embeddings, collection_name=\"sajith_premadasa\")\n",
    "# retriever_sajith = vectorstore_sajith.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "# # akd's manifesto\n",
    "# vectorstore_akd = Chroma(persist_directory=persist_directory, embedding_function=embeddings, collection_name=\"anura_kumara_dissanayake\")\n",
    "# retriever_akd = vectorstore_akd.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "# # ranil's manifesto\n",
    "# vectorstore_ranil = Chroma(persist_directory=persist_directory, embedding_function=embeddings, collection_name=\"ranil_wickramasinghe\")\n",
    "# retriever_ranil = vectorstore_ranil.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "# contextualize_q_system_prompt = (\n",
    "#     \"Given a chat history and the latest user question \"\n",
    "#     \"which might reference context in the chat history, \"\n",
    "#     \"formulate a standalone question which can be understood \"\n",
    "#     \"without the chat history. Do NOT answer the question, \"\n",
    "#     \"just reformulate it if needed and otherwise return it as is.\"\n",
    "# )\n",
    "\n",
    "# contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", contextualize_q_system_prompt),\n",
    "#         MessagesPlaceholder(\"chat_history\"),\n",
    "#         (\"human\", \"{input}\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# history_aware_retriever_general = create_history_aware_retriever(\n",
    "#     llm, retriever_general, contextualize_q_prompt\n",
    "# )\n",
    "\n",
    "# history_aware_retriever_sajith = create_history_aware_retriever(\n",
    "#     llm, retriever_sajith, contextualize_q_prompt\n",
    "# )\n",
    "\n",
    "# history_aware_retriever_akd = create_history_aware_retriever(\n",
    "#     llm, retriever_akd, contextualize_q_prompt\n",
    "# )\n",
    "\n",
    "# history_aware_retriever_ranil = create_history_aware_retriever(\n",
    "#     llm, retriever_ranil, contextualize_q_prompt\n",
    "# )\n",
    "\n",
    "# retrievers = {\n",
    "#     \"sajith_premadasa\": retriever_sajith,\n",
    "#     \"anura_kumara_dissanayake\": retriever_akd,\n",
    "#     \"ranil_wickramasinghe\": retriever_ranil,\n",
    "# }\n",
    "\n",
    "# class SearchAndCompare(BaseModel):\n",
    "#     \"\"\"Search for information about a person or compare informations about persons.\"\"\"\n",
    "#     queryType: str = Field(\n",
    "#         ...,\n",
    "#         description=\"Query type. Should be `search` or `compare` or `general`. if there's only one person name it's search, if there are many person's name it's compare, or it can be a general question which does not require any specific person\",)\n",
    "\n",
    "#     query: str = Field(\n",
    "#         ...,\n",
    "#         description=\"Query to look up or query to compare\",\n",
    "#     )\n",
    "\n",
    "#     candidates: int = Field(\n",
    "#         ...,\n",
    "#         description=\"Number of persons to search or compare. can be 0 for general questions\",\n",
    "#     )\n",
    "\n",
    "#     person1: str = Field(\n",
    "#         ...,\n",
    "#         description=\"Person to look things up for or persons to compare. Should be `sajith_premadasa` or `anura_kumara_dissanayake` or `ranil_wickramasinghe` or can be 'null'.\",\n",
    "#     )\n",
    "#     person2: str = Field(\n",
    "#         ...,\n",
    "#         description=\"Person to look things up for or persons to compare. Should be `sajith_premadasa` or `anura_kumara_dissanayake` or `ranil_wickramasinghe` or can be 'null'.\",\n",
    "#     )\n",
    "#     person3: str = Field(\n",
    "#         ...,\n",
    "#         description=\"Person to look things up for or persons to compare. Should be `sajith_premadasa` or `anura_kumara_dissanayake` or `ranil_wickramasinghe` or can be 'null'.\",\n",
    "#     )\n",
    "\n",
    "# structured_llm_query = llm.with_structured_output(SearchAndCompare)\n",
    "\n",
    "# @chain\n",
    "# def query_analyzer_chain(question):\n",
    "#     system_query = \"\"\"You have the ability to determine whether the user question is general, or it is related to a specific person or it is a comparison between multiple persons. if you can't find the type set it as general\"\"\"\n",
    "#     prompt_query = ChatPromptTemplate.from_messages(\n",
    "#         [\n",
    "#             (\"system\", system_query),\n",
    "#             (\"human\", \"{question}\"),\n",
    "#         ]\n",
    "#     )\n",
    "#     prompt_query = prompt_query.format_messages(question=question)\n",
    "#     response = structured_llm_query.invoke(prompt_query)\n",
    "\n",
    "#     return response\n",
    "\n",
    "\n",
    "# @chain\n",
    "# def qa_chain(question):\n",
    "#     response = query_analyzer_chain.invoke(question)\n",
    "#     # print(response)\n",
    "#     if response.queryType == \"search\" or response.queryType == \"compare\":\n",
    "#         if response.queryType == \"search\":\n",
    "#             retriever = retrievers[response.person1]\n",
    "#             retrieved_docs = retriever.invoke(response.query)\n",
    "\n",
    "#             prompt = (\n",
    "#             \"system :\"\n",
    "#             \"You are an assistant for question-answering tasks. \"\n",
    "#             \"Use the following pieces of retrieved context to answer \"\n",
    "#             \"the question. If you don't know the answer, say that you \"\n",
    "#             \"don't know.\"\n",
    "#             \"\\n\\n\"\n",
    "#             \"{context}\"\n",
    "#             \"\\n\\n\"\n",
    "\n",
    "#             \"chat_history :\" \n",
    "#             \"{chat_history}\"\n",
    "\n",
    "#             \"human :\"\n",
    "#             \"{question}\"\n",
    "#             ).format(context=retrieved_docs, question=question, chat_history=chat_history)\n",
    "\n",
    "#             result = llm.invoke(prompt)\n",
    "\n",
    "#             return result\n",
    "    \n",
    "#         elif response.queryType == \"compare\":\n",
    "#             retriever1 = retrievers[response.person1]\n",
    "#             retrieved_docs1 = retriever1.invoke(response.query)\n",
    "\n",
    "#             if response.person2 != 'null':\n",
    "#                 retriever2 = retrievers[response.person2]\n",
    "#                 retrieved_docs2 = retriever2.invoke(response.query)\n",
    "#             else:\n",
    "#                 retrieved_docs2 = ''\n",
    "\n",
    "#             if response.person3 != 'null':\n",
    "#                 retriever3 = retrievers[response.person3]\n",
    "#                 retrieved_docs3 = retriever3.invoke(response.query)\n",
    "#             else:\n",
    "#                 retrieved_docs3 = ''\n",
    "\n",
    "#             prompt = (\n",
    "#             \"system :\"\n",
    "#             \"You are an assistant for comparing manifestos. \"\n",
    "#             \"Use the following pieces of retrieved context from different manifestos to answer \"\n",
    "#             \"the question. If you don't know the answer, say that you \"\n",
    "#             \"don't know.\"\n",
    "#             \"\\n\\n\"\n",
    "#             \"{context1}\"\n",
    "#             \"\\n\\n\"\n",
    "#             \"{context2}\"\n",
    "#             \"\\n\\n\"\n",
    "#             \"{context3}\"\n",
    "#             \"\\n\\n\"\n",
    "\n",
    "#             \"chat_history :\" \n",
    "#             \"{chat_history}\"\n",
    "\n",
    "#             \"human :\"\n",
    "#             \"{question}\"\n",
    "#             ).format(context1=retrieved_docs1, context2=retrieved_docs2, context3=retrieved_docs3, question=question, chat_history=chat_history)\n",
    "\n",
    "#             result = llm.invoke(prompt)\n",
    "\n",
    "#             return result\n",
    "#     else:\n",
    "#         retriever = retriever_general\n",
    "#         retrieved_docs = retriever.invoke(response.query)\n",
    "\n",
    "#         prompt = (\n",
    "#             \"system :\"\n",
    "#             \"You are an assistant for question-answering tasks related to srilankan election.\"\n",
    "#             \"Use the following pieces of retrieved context to answer \"\n",
    "#             \"the question. If you don't know the answer, say that you \"\n",
    "#             \"don't know.\"\n",
    "#             \"or if the question is not much related to srilankan election say that this question is not related to srilankan election ass a election chatbot i can't provide you with answer this.\"\n",
    "#             \"\\n\\n\"\n",
    "#             \"{context}\"\n",
    "#             \"\\n\\n\"\n",
    "\n",
    "#             \"chat_history :\" \n",
    "#             \"{chat_history}\"\n",
    "\n",
    "#             \"human :\"\n",
    "#             \"{question}\"\n",
    "#             ).format(context=retrieved_docs, question=question, chat_history=chat_history)\n",
    "\n",
    "#         result = llm.invoke(prompt)\n",
    "#         return result\n",
    "\n",
    "# def chatbot(question):\n",
    "#     result = qa_chain.invoke(question)\n",
    "    \n",
    "#     # retains only last 3 conversations in history\n",
    "#     if len(chat_history) == 6:\n",
    "#         chat_history.pop(0)\n",
    "#         chat_history.pop(0)\n",
    "    \n",
    "#     chat_history.extend([\n",
    "#             HumanMessage(content=question),\n",
    "#             AIMessage(content=result.content),\n",
    "#         ])\n",
    "    \n",
    "#     return result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chromadb\n",
    "# from chromadb.config import Settings\n",
    "# class Chat_db:\n",
    "#     def __init__(self, persist_directory=\"local_chroma_db\"):\n",
    "#         self.persist_directory = persist_directory             \n",
    "#         self.client_settings = Settings(is_persistent= True, persist_directory= persist_directory, anonymized_telemetry=False)\n",
    "#         self.persistent_client = chromadb.Client(settings= self.client_settings)\n",
    "#         self.doc_collection = self.persistent_client.get_or_create_collection(name = \"general\")\n",
    "       \n",
    "#         #I thought I could just use self.persistent_client for querying but it did not work. \n",
    "#         # had to create a PersistentClient to use for querying.\n",
    "#         self.queryclient = chromadb.PersistentClient(path= persist_directory, settings= self.client_settings)\n",
    "        \n",
    "\n",
    "#     def chat_over_documents(self, collection_name, query, k = 5):\n",
    "#         collection = self.queryclient.get_collection(name=collection_name)\n",
    "#         results = collection.query(query_texts= query, n_results= k)\n",
    "#         flat_results = [item for sublist in results['documents'] for item in sublist] \n",
    "#         return flat_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_handler = Chat_db()\n",
    "\n",
    "# response = document_handler.chat_over_documents(query=\"ranil\", collection_name=\"general\",k=5)\n",
    "\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a comparison of what Sajith, Anura, and Ranil said about education in their manifestos:\n",
       "\n",
       "**Sajith Premadasa:**\n",
       "\n",
       "* **Focus on quality and accessibility:**  He emphasizes making education more accessible and improving its quality to build a competitive workforce.\n",
       "* **Smart Schools:**  He aims to transform every school into a smart school with 100% electricity, water facilities, and physical resources.\n",
       "* **Digital Learning:**  He plans to expand the \"Sakwala\" program to provide access to digital learning platforms in schools, technical and vocational institutions, and universities.\n",
       "* **Teacher Support:**  He promises free public transportation for all teachers and plans to address salary, pension, and service issues in the education sector.\n",
       "* **Early Childhood Education:**  He recognizes the importance of ECE and plans to establish a regulatory authority with a multi-stakeholder advisory committee.\n",
       "* **\"STEEAM\" Education:**  He wants to prioritize Science, Technology, English, Engineering, Arts, and Mathematics in all institutions by January 2025.\n",
       "* **English Proficiency:**  He aims to design primary and secondary education with modern technology to enable students to understand, speak, and write English from an early stage.\n",
       "* **Vocational Training:**  He plans to modernize and standardize vocational training curricula to align with market demands.\n",
       "\n",
       "**Anura Dissanayake:**\n",
       "\n",
       "* **Engineering Education Reform:**  He focuses on reforming and restructuring engineering education to produce industry-related practitioners.\n",
       "* **Equal Education Opportunities:**  He aims to provide equal education opportunities around the country with free access to education materials.\n",
       "* **Promoting IoT Applications:**  He wants to promote IoT applications for the development of IoT networks (e.g., smart metering).\n",
       "* **Terrestrial TV for Education:**  He identifies terrestrial TV as an efficient medium for educational services and plans to improve technical infrastructure.\n",
       "\n",
       "**Ranil Wickremesinghe:**\n",
       "\n",
       "* **Modernizing School Infrastructure:**  He acknowledges the need to modernize school infrastructure to meet the demands of the technological era.\n",
       "* **Teacher Training:**  He plans to equip teachers with new knowledge and training in 2025.\n",
       "* **School Boards:**  He aims to complete the establishment of School Boards with representatives from School Development Societies and Past Pupils Associations by 2027.\n",
       "* **Soft Skills and Moral Values:**  He wants to revise school education with a focus on soft skills, life skills, and moral values.\n",
       "* **\"English for All\" Program:**  He plans to implement an \"English for All\" program to provide English education to all schoolchildren within the next decade.\n",
       "* **Vocational Skills Sri Lanka (VSSL):**  He proposes establishing a new entity called VSSL in 2025 to amalgamate the National Apprentice and Industrial Training Authority and the Vocational Training Authority of Sri Lanka.\n",
       "* **Provincial Vocational Education Boards:**  He aims to establish Provincial Vocational Education Boards in all nine provinces by the end of 2026.\n",
       "* **Technical and Vocational and Management University Colleges:**  He plans to open these colleges in all provinces with faculties in all districts.\n",
       "\n",
       "**Key Differences:**\n",
       "\n",
       "* **Sajith** focuses on making education more accessible and improving its quality, with a strong emphasis on digital learning and teacher support.\n",
       "* **Anura** focuses on reforming engineering education and promoting technology in education.\n",
       "* **Ranil** focuses on modernizing school infrastructure, improving teacher training, and promoting soft skills and moral values.\n",
       "\n",
       "**Similarities:**\n",
       "\n",
       "* All three candidates recognize the importance of education and have plans to improve it in various ways.\n",
       "* They all emphasize the need for a skilled workforce and the importance of technology in education. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"what sajith and anura and ranil said about education\"\n",
    "display(Markdown(chatbot(question)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
