{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough, chain\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "class ChatbotService:\n",
    "    def _init_(self):\n",
    "        # Load environment variables from .env file\n",
    "        load_dotenv()\n",
    "\n",
    "        # Get the API key from environment variables\n",
    "        self.api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "        # Initialize embeddings and LLM\n",
    "        self.embeddings = GoogleGenerativeAIEmbeddings(api_key=self.api_key, model=\"models/embedding-001\")\n",
    "        self.llm = ChatGoogleGenerativeAI(api_key=self.api_key, model=\"gemini-1.5-flash\", temperature=0.3, max_tokens=1000)\n",
    "        self.chat_history = []\n",
    "\n",
    "        # Initialize vectorstores and retrievers\n",
    "        self.vectorstores = {\n",
    "            \"general\": Chroma(persist_directory=\"local_chroma_db\", embedding_function=self.embeddings, collection_name=\"general\"),\n",
    "            \"sajith_premadasa\": Chroma(persist_directory=\"local_chroma_db\", embedding_function=self.embeddings, collection_name=\"sajith_premadasa\"),\n",
    "            \"anura_kumara_dissanayake\": Chroma(persist_directory=\"local_chroma_db\", embedding_function=self.embeddings, collection_name=\"anura_kumara_dissanayake\"),\n",
    "            \"ranil_wickramasinghe\": Chroma(persist_directory=\"local_chroma_db\", embedding_function=self.embeddings, collection_name=\"ranil_wickramasinghe\"),\n",
    "        }\n",
    "        \n",
    "        self.retrievers = {\n",
    "            \"sajith_premadasa\": self.vectorstores[\"sajith_premadasa\"].as_retriever(search_kwargs={\"k\": 10}),\n",
    "            \"anura_kumara_dissanayake\": self.vectorstores[\"anura_kumara_dissanayake\"].as_retriever(search_kwargs={\"k\": 10}),\n",
    "            \"ranil_wickramasinghe\": self.vectorstores[\"ranil_wickramasinghe\"].as_retriever(search_kwargs={\"k\": 10}),\n",
    "            \"general\": self.vectorstores[\"general\"].as_retriever(search_kwargs={\"k\": 10}),\n",
    "        }\n",
    "\n",
    "        # Define system prompts\n",
    "        self.contextualize_q_system_prompt = (\n",
    "            \"Given a chat history and the latest user question \"\n",
    "            \"which might reference context in the chat history, \"\n",
    "            \"formulate a standalone question which can be understood \"\n",
    "            \"without the chat history. Do NOT answer the question, \"\n",
    "            \"just reformulate it if needed and otherwise return it as is.\"\n",
    "        )\n",
    "\n",
    "        self.contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.contextualize_q_system_prompt),\n",
    "                MessagesPlaceholder(\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Initialize history aware retrievers\n",
    "        self.history_aware_retrievers = {\n",
    "            key: create_history_aware_retriever(self.llm, retriever, self.contextualize_q_prompt)\n",
    "            for key, retriever in self.retrievers.items()\n",
    "        }\n",
    "\n",
    "        # Define query system prompt\n",
    "        self.system_query = \"\"\"You have the ability to determine whether the user question is general, or it is related to a specific person or it is a comparison between multiple persons. if you can't find the type set it as general\"\"\"\n",
    "        self.prompt_query = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.system_query),\n",
    "                (\"human\", \"{question}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.structured_llm_query = self.llm.with_structured_output(SearchAndCompare)\n",
    "        self.query_analyzer = {\"question\": RunnablePassthrough()} | self.prompt_query | self.structured_llm_query\n",
    "\n",
    "    def qa_chain(self, question):\n",
    "        # Log the incoming question\n",
    "        print(f\"Question: {question}\")\n",
    "        \n",
    "        # Analyze the query\n",
    "        response = self.query_analyzer.invoke(question)\n",
    "        print(f\"Query Analyzer Response: {response}\")\n",
    "        \n",
    "        # Handle search or comparison\n",
    "        if response.queryType in [\"search\", \"compare\"]:\n",
    "            if response.queryType == \"search\":\n",
    "                retriever = self.history_aware_retrievers.get(response.person1, self.history_aware_retrievers[\"general\"])\n",
    "                print(\"Retriever ISSSS !!!: \", retriever)\n",
    "                \n",
    "                retrieved_docs = retriever.invoke({\"input\": response.query, \"chat_history\": self.chat_history})\n",
    "                \n",
    "                # Log retrieved documents\n",
    "                print(f\"Retrieved Docs: {retrieved_docs}\")\n",
    "\n",
    "                prompt = (\n",
    "                    \"system :\"\n",
    "                    \"You are an assistant for question-answering tasks. \"\n",
    "                    \"Use the following pieces of retrieved context to answer \"\n",
    "                    \"the question. If you don't know the answer, say that you \"\n",
    "                    \"don't know.\"\n",
    "                    \"\\n\\n\"\n",
    "                    \"{context}\"\n",
    "                    \"\\n\\n\"\n",
    "                    \"chat_history :\" \n",
    "                    \"{chat_history}\"\n",
    "                    \"human :\"\n",
    "                    \"{question}\"\n",
    "                ).format(context=retrieved_docs, question=question, chat_history=self.chat_history)\n",
    "\n",
    "                # Log the prompt\n",
    "                print(f\"Prompt: {prompt}\")\n",
    "                \n",
    "                result = self.llm.invoke(prompt)\n",
    "                return result\n",
    "\n",
    "            elif response.queryType == \"compare\":\n",
    "                retrieved_docs = []\n",
    "                for person in [response.person1, response.person2, response.person3]:\n",
    "                    if person != 'null':\n",
    "                        retriever = self.history_aware_retrievers.get(person, self.history_aware_retrievers[\"general\"])\n",
    "                        docs = retriever.invoke({\"input\": response.query, \"chat_history\": self.chat_history})\n",
    "                        retrieved_docs.append(docs)\n",
    "                    else:\n",
    "                        retrieved_docs.append('')\n",
    "\n",
    "                prompt = (\n",
    "                    \"system :\"\n",
    "                    \"You are an assistant for comparing manifestos. \"\n",
    "                    \"Use the following pieces of retrieved context from different manifestos to answer \"\n",
    "                    \"the question. If you don't know the answer, say that you \"\n",
    "                    \"don't know.\"\n",
    "                    \"\\n\\n\"\n",
    "                    \"{context1}\"\n",
    "                    \"\\n\\n\"\n",
    "                    \"{context2}\"\n",
    "                    \"\\n\\n\"\n",
    "                    \"{context3}\"\n",
    "                    \"\\n\\n\"\n",
    "                    \"chat_history :\" \n",
    "                    \"{chat_history}\"\n",
    "                    \"human :\"\n",
    "                    \"{question}\"\n",
    "                ).format(context1=retrieved_docs[0], context2=retrieved_docs[1], context3=retrieved_docs[2], question=question, chat_history=self.chat_history)\n",
    "\n",
    "                # Log the prompt\n",
    "                print(f\"Prompt: {prompt}\")\n",
    "                \n",
    "                result = self.llm.invoke(prompt)\n",
    "                return result\n",
    "        else:\n",
    "            retriever = self.history_aware_retrievers[\"general\"]\n",
    "            retrieved_docs = retriever.invoke({\"input\": response.query, \"chat_history\": self.chat_history})\n",
    "\n",
    "            # Log retrieved documents\n",
    "            print(f\"Retrieved Docs: {retrieved_docs}\")\n",
    "\n",
    "            prompt = (\n",
    "                \"system :\"\n",
    "                \"You are an assistant for question-answering tasks related to srilankan election.\"\n",
    "                \"Use the following pieces of retrieved context to answer \"\n",
    "                \"the question. If you don't know the answer, say that you \"\n",
    "                \"don't know.\"\n",
    "                \"or if the question is not much related to srilankan election say that this question is not related to srilankan election as a election chatbot i can't provide you with answer this.\"\n",
    "                \"\\n\\n\"\n",
    "                \"{context}\"\n",
    "                \"\\n\\n\"\n",
    "                \"chat_history :\" \n",
    "                \"{chat_history}\"\n",
    "                \"human :\"\n",
    "                \"{question}\"\n",
    "            ).format(context=retrieved_docs, question=question, chat_history=self.chat_history)\n",
    "\n",
    "            # Log the prompt\n",
    "            print(f\"Prompt: {prompt}\")\n",
    "            \n",
    "            result = self.llm.invoke(prompt)\n",
    "            return result\n",
    "\n",
    "    def chatbot(self, question):\n",
    "        result = self.qa_chain(question)\n",
    "        print(f\"Chatbot Result: {result}\")\n",
    "        # Retain only last 3 conversations in history\n",
    "        if len(self.chat_history) >= 6:\n",
    "            self.chat_history = self.chat_history[-3:]\n",
    "        \n",
    "        self.chat_history.extend([\n",
    "            HumanMessage(content=question),\n",
    "            AIMessage(content=result.content),\n",
    "        ])\n",
    "        \n",
    "        return result.content\n",
    "\n",
    "class SearchAndCompare(BaseModel):\n",
    "    \"\"\"Search for information about a person or compare informations about persons.\"\"\"\n",
    "    queryType: str = Field(\n",
    "        ...,\n",
    "        description=\"Query type. Should be search or compare or general. if there's only one person name it's search, if there are many person's name it's compare, or it can be a general question which does not require any specific person\",\n",
    "    )\n",
    "\n",
    "    query: str = Field(\n",
    "        ...,\n",
    "        description=\"Query to look up or query to compare\",\n",
    "    )\n",
    "\n",
    "    candidates: int = Field(\n",
    "        ...,\n",
    "        description=\"Number of persons to search or compare. can be 0 for general questions\",\n",
    "    )\n",
    "\n",
    "    person1: str = Field(\n",
    "        ...,\n",
    "        description=\"Person to look things up for or persons to compare. Should be sajith_premadasa or anura_kumara_dissanayake or ranil_wickramasinghe or can be 'null'.\",\n",
    "    )\n",
    "    person2: str = Field(\n",
    "        ...,\n",
    "        description=\"Person to look things up for or persons to compare. Should be sajith_premadasa or anura_kumara_dissanayake or ranil_wickramasinghe or can be 'null'.\",\n",
    "    )\n",
    "    person3: str = Field(\n",
    "        ...,\n",
    "        description=\"Person to look things up for or persons to compare. Should be sajith_premadasa or anura_kumara_dissanayake or ranil_wickramasinghe or can be 'null'.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Compare ranil with anura\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ChatbotService' object has no attribute 'query_analyzer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m chatbot_service \u001b[38;5;241m=\u001b[39m ChatbotService()\n\u001b[0;32m      3\u001b[0m questions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompare ranil with anura\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mchatbot_service\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchatbot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[1], line 180\u001b[0m, in \u001b[0;36mChatbotService.chatbot\u001b[1;34m(self, question)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchatbot\u001b[39m(\u001b[38;5;28mself\u001b[39m, question):\n\u001b[1;32m--> 180\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqa_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatbot Result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;66;03m# Retain only last 3 conversations in history\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 81\u001b[0m, in \u001b[0;36mChatbotService.qa_chain\u001b[1;34m(self, question)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Analyze the query\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_analyzer\u001b[49m\u001b[38;5;241m.\u001b[39minvoke(question)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery Analyzer Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Handle search or comparison\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ChatbotService' object has no attribute 'query_analyzer'"
     ]
    }
   ],
   "source": [
    "chatbot_service = ChatbotService()\n",
    "\n",
    "questions = [\"Compare ranil with anura\"]\n",
    "\n",
    "print(chatbot_service.chatbot(questions[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
